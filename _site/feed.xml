<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Vishwajeet</title>
    <description>Robotics portfolio | Vishwajeet Bhgyawant
</description>
    <link>robotics portfolio/</link>
    <atom:link href="robotics portfolio/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Wed, 19 May 2021 19:01:18 +0530</pubDate>
    <lastBuildDate>Wed, 19 May 2021 19:01:18 +0530</lastBuildDate>
    <generator>Jekyll v4.2.0</generator>
    
      <item>
        <title>Research Project</title>
        <description>&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;header&gt;
        &lt;!-- &lt;h2&gt;Multi Agent Patrolling&lt;/h2&gt; --&gt;
        &lt;p&gt;Guides: &lt;a href=&quot;https://www.sc.iitb.ac.in/~leena/&quot;&gt;Prof. Leena Vachhani&lt;/a&gt; &amp; &lt;a
                href=&quot;https://www.sc.iitb.ac.in/~asinha/&quot;&gt;Prof. Arpita Sinha&lt;/a&gt;&lt;/p&gt;
    &lt;/header&gt;
&lt;/div&gt;

&lt;h3&gt;Project Description:&lt;/h3&gt;
&lt;p&gt;
&lt;p&gt;&lt;span class=&quot;image right&quot;&gt;&lt;img src=&quot;/images/projects/pat/pat.gif&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
Patrolling means the act of walking or traveling around an area, at regular intervals, to protect or supervise it. Given a graph, the patrolling task refers to continuously visiting all the graph nodes to minimize the time lag between two visits. We have to design an automated patrolling system with multiple agents to monitor a given environment with nodes of interest of varying priorities. A group of students is working on the simulation part of this project, provided by the DRDO, India. They will do the hardware aspect of this project. This project's main objective is to prevent the innocent lives of many soldiers who are at the borders working at their top edge and died while patrolling manually. So, instead of them, an autonomous car will do this task and keep a keen observation of the enemies' movement.
&lt;/p&gt;
&lt;a href=&quot;/assets/multi_agent_patrolling_report.pdf&quot; class=&quot;button &quot; target=&quot;blank&quot;&gt;Project Report&lt;/a&gt;
&lt;br&gt;
&lt;hr&gt;
&lt;h3&gt;My Learnings &amp; Contribution till date:&lt;/h3&gt;
&lt;p&gt;
    &lt;li&gt;Proposed a novel technique for Multi-Robot Patrolling using IoT devices for a secured, decentralised decision making and robust solution against device failures.
    &lt;/li&gt;&lt;br&gt;
    &lt;li&gt;Developed a local, reactive, decentralized algorithm (MRPP-IoT) to minimize Graph Idleness with IoT devices at Junctions as the decision-making units.
    &lt;/li&gt;&lt;br&gt;
    &lt;li&gt;Analyzed patrolling performance of MRPP-IoT algorithm based on an extensive and systematic set of simulations carried out on SUMO (a traffic simulator). 
    &lt;/li&gt;&lt;br&gt;
    &lt;li&gt;Comparison of the MRPP-IoT algorithm with two states of the art strategies - Conscientious Reactive as well as Reactive with Flags 2 [8] demonstrate the possibility of a decentralised solution for MRPP that maintains the uniformity of patrolling even during device failures.
    &lt;/li&gt;&lt;br&gt;
    &lt;li&gt;Applied Conscientious Reactive architecture with emergent coordination strategy for reducing idleness using Traci library in a realistic traffic simulator - Simulation of Urban MObility (SUMO)
    &lt;/li&gt;&lt;br&gt;
    &lt;li&gt;This project gave me an insight into Reinforcement Learning in my second year. Created an algorithm for decision making based on RL Techniques and tested it on platforms like MIT DeepTraffic Simulator and Unity ML-Agents. This algorithm helps in making decisions like accelerating, decelerating, left &amp; right based on the surrounding.
    &lt;/li&gt;&lt;br&gt;
    &lt;li&gt;During my learning period, I applied the RL method using ROS and gazebo and simulated a self-balancing inverse pendulum, which learns to balance itself from previous experience
    &lt;/li&gt;&lt;br&gt;
        &lt;div class=&quot;row uniform 50%&quot;&gt;
            &lt;div class=&quot;6u&quot;&gt;&lt;span class=&quot;image fit&quot; style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/images/projects/pat/pat4.gif&quot; alt=&quot;&quot; /&gt; Simulation in gazebo&lt;/span&gt;&lt;/div&gt;
            &lt;div class=&quot;6u&quot;&gt;&lt;span class=&quot;image fit&quot; style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/images/projects/pat/pat5.jpg&quot; alt=&quot;&quot; /&gt;Results&lt;/span&gt;&lt;/div&gt;
        &lt;/div&gt;

&lt;/p&gt;
</description>
        <pubDate>Sat, 31 Oct 2020 00:00:00 +0530</pubDate>
        <link>robotics portfolio/projects/patrolling</link>
        <guid isPermaLink="true">robotics portfolio/projects/patrolling</guid>
        
        
      </item>
    
      <item>
        <title>IARC Mission 9.0</title>
        <description>        &lt;div style=&quot;text-align: center;&quot;&gt;
                &lt;h4&gt;Winners of International Aerial Robotics Challenge!!!!&lt;/h4&gt;
                &lt;img src=&quot;/images/projects/iarc/win3.gif&quot; class=&quot;image&quot; style=&quot;max-width:35%;&quot; alt=&quot;&quot;&gt;
            &lt;/div&gt;
&lt;/p&gt;



&lt;h3&gt;About Team Aerov&lt;/h3&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
        &lt;img src=&quot;/images/projects/aerov.png&quot; class=&quot;image&quot; style=&quot;max-width: 50%; vertical-align:middle;&quot; alt=&quot;&quot;&gt;
&lt;/div&gt;
&lt;p&gt; I am working in Team Aerove. Team Aerove is a part of UMIC ( &lt;a href=&quot;https://www.umiciitb.com/&quot; target=&quot;blank&quot;&gt;Umesh Mashruwal Innovation
                Cell&lt;/a&gt; ), Student Technical Team at IIT Bombay.
        The team focuses on Aerial robots related competition in worldwide.
        It has already participated in IARC Mission 7 and Barcelona Smart Drone challenge.
        Currently, it finished wining IARC Mission 9. 
&lt;hr /&gt;
&lt;h3&gt;About IARC &lt;/h3&gt;
&lt;p&gt;The Association for Unmanned Vehicle Systems International Foundation's International Aerial Robotics Competition is the longest-running collegiate aerial robotics challenge in the world, having celebrated its quarter-century anniversary in 2016. This time, IARC Mission was based on simulat.
        The detailed problem statement for IARC Mission 9 can be found &lt;a
        href=&quot;http://www.aerialroboticscompetition.org/&quot; target=&quot;blank&quot;&gt;here&lt;/a&gt;. Mission includes
        Mid-air drone deployment, performing operations with end effector attached to the droneion &lt;/p&gt;
&lt;hr&gt;
&lt;h3&gt;Project Description&lt;/h3&gt;
&lt;h4&gt;The Idea&lt;/h4&gt;
&lt;p&gt;
        For tackling the IARC 2020 Challenge, We decided to go with a Mothership-Daughtership configuration, which would increase effectiveness and save time. A key constraint governing our strategy of module replacement is time constraint. 
        The major drawback of using a single drone is that it decreases the time available for communication module replacement. Therefore a mother-daughter drone configuration will buy us the time of the entire return flight. Also, the weight of the Mothership decreases during return flight which allows it to achieve a higher maximum speed.  The mothership carries the daughtership up to the drop point, and then circles back to the start point. Meanwhile, 
        the daughtership undertakes the arduous task of replacing the communication module on on the swaying mast
&lt;/p&gt;


&lt;ul class=&quot;tab actions fit&quot;&gt;
        &lt;li&gt;&lt;button class=&quot;tablinks active  button fit&quot; id=&quot;One&quot;&gt;Mechanical&lt;/button&gt;&lt;/li&gt;
        &lt;li&gt;&lt;button class=&quot;tablinks button fit&quot; id=&quot;Two&quot;&gt;Controls&lt;/button&gt;&lt;/li&gt;
        &lt;li&gt;&lt;button class=&quot;tablinks button fit&quot; id=&quot;Three&quot;&gt;Localisation and ML&lt;/button&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div id=&quot;One&quot; class=&quot;tabcontent&quot;&gt;
        &lt;div style=&quot;text-align: center;&quot;&gt;
                &lt;h3&gt;The Mothership&lt;/h3&gt;
                &lt;img src=&quot;/images/projects/iarc/mother.jpeg&quot; class=&quot;image&quot; style=&quot;max-width:50%;&quot; alt=&quot;&quot;&gt;
        &lt;/div&gt;
        &lt;p&gt;The mothership is the primary drone that carries the secondary daughter drone. It is an autonomous 25 Kg hexacopter with an integral cage-like structure. The mothership will deploy the daughter drone at the mast and continue its way homeward to complete the mission in 9 minutes.&lt;/p&gt;
        &lt;h4&gt;Key features&lt;/h4&gt;
        &lt;ul&gt;
                &lt;li&gt;Equipped with six powerful MN1010 motors to carry the heavy daughter drone&lt;/li&gt;
                &lt;li&gt;Powered by four 16000 mAh LIPO batteries to achieve a flight time of 11 min&lt;/li&gt;
                &lt;li&gt;Equipped with a launchpad for the mid-air take-off of the daughter drone&lt;/li&gt;
                &lt;li&gt;It has a cage-like structure to reduce weight while maintaining strengthTry it now!&lt;/li&gt;
        &lt;/ul&gt;
        &lt;div style=&quot;text-align: center;&quot;&gt;
                &lt;h3&gt;The Daughtership&lt;/h3&gt;
                &lt;img src=&quot;/images/projects/iarc/mother.jpeg&quot; class=&quot;image&quot; style=&quot;max-width:50%;&quot; alt=&quot;&quot;&gt;
        &lt;/div&gt;
        &lt;p&gt;The daughter drone, a 25 kg autonomous coaxial-octocopter capable of launching in mid-air, is meant to replace the communication module. It is equipped with a Pixhawk 4 for controlling the drone during flight. Intel Realsense D435 for obtaining live video feed of the surroundings, Intel NUC 5i5RYH onboard computation, Here3 GPS for localisation, and 7 DOF robotic arm for gripping the mast and replacing the module. 
                &lt;br&gt;
                Further, the daughter drone is enabled with an intelligent system that removes the rigid connection between the drone and the replacement mechanism, leaving them connected by ropes. So, after grabbing the mast, the mast’s motion isn’t transferred to the drone.
                The daughter drone has an in-built mechanism which utilises gears and chains to facilitate the motion of the replacement mechanism and provide it extra accuracy.
                The frame of the drone is built so as to reduce drag and provide better aerodynamic efficiency.&lt;/p&gt;
                &lt;h4&gt;Key features&lt;/h4&gt;
                &lt;ul&gt;
                        &lt;li&gt;It has a stretched-X frame so that the drone can go closer to the mast while keeping the COM close to the centre of the frame.&lt;/li&gt;
                        &lt;li&gt;Reducing size &amp; weight using coaxial-configuration and a 3-blade propeller&lt;/li&gt;
                        &lt;li&gt;The frame is attached with the replacement mechanism to provide it with 3 degrees of transnational motions.&lt;/li&gt;
                &lt;/ul&gt;
        

        &lt;div style=&quot;text-align: center;&quot;&gt;
        &lt;h3&gt;The Gripping Mechanism &lt;/h3&gt;
        &lt;img src=&quot;/images/projects/iarc/mechanism.jpeg&quot; class=&quot;image&quot; style=&quot;max-width:50%;&quot; alt=&quot;&quot;&gt;
        &lt;/div&gt;
        &lt;br&gt;
                &lt;h4&gt;Maneuvers for module replacement&lt;/h4&gt;
                &lt;ol&gt;
                        &lt;li&gt;The first step comprises lowering the gripper and grabbing the swaying mast, thus ceasing any relative motion between the gripping mechanism and the mast.&lt;/li&gt;
                        &lt;li&gt;Next, the communication module is extracted from the mast by employing a specially designed gripper which will slide onto the module’s antenna and pull it out using a linear actuator. As soon as the module loses contact with the guiding rods, it will fall automatically.                        &lt;/li&gt;
                        &lt;li&gt;Now the replacement module can be slid into place, completing the process of module replacement.&lt;/li&gt;
                &lt;/ol&gt;
        &lt;hr&gt;
&lt;/div&gt;

&lt;div id=&quot;Two&quot; class=&quot;tabcontent&quot;&gt;
        &lt;p style=&quot;text-align: center;&quot;&gt;Controls Subsystem deals with preparing the simulation environment, autonomous navigation of multiple UAVs using PX4-SITL, mid-aid drone deployment, joint controllers for replacement mechanism, and tuning of flight controller parameters and PID gains.
                GzWeb, Gazebo's WebGL client provides front-end graphical interface to the gzserver and interactive visualisation of the simulation in your web browser. ngrok is used for tunneling the simulation from local host to the public internet. A real time Firebase database is used to update the slider values.  &lt;/p&gt; 
        &lt;div style=&quot;text-align: center;&quot;&gt;
                &lt;h3&gt;Gazebo Simulation Environment&lt;/h3&gt;
                &lt;img src=&quot;/images/projects/iarc/gazebo.png&quot; class=&quot;image&quot; style=&quot;max-width:50%;&quot; alt=&quot;&quot;&gt;
        &lt;/div&gt;
        &lt;p&gt;We have used Gazebo 9 as our primary 3D simulator backed by ROS Melodic. Gazebo utilizes the high-performance physics engine ODE (Open Dynamics Engine). It provides a realistic rendering of environments, including high-quality lighting, shadows, and textures.&lt;/p&gt;
        `
        
        &lt;div style=&quot;text-align: center;&quot;&gt;
                &lt;h3&gt;PX4 SITL Flight Stack&lt;/h3&gt;
                &lt;img src=&quot;/images/projects/iarc/sitl.gif&quot; class=&quot;image&quot; style=&quot;max-width:50%;&quot; alt=&quot;&quot;&gt;
        &lt;/div&gt;
        &lt;p&gt;The PX4 Software in the loop (SITL) package formed our drone control's backbone and was used to execute the mission trajectories and other complicated manoeuvres. This package mimics the performance of the flight controller in simulation, hence giving close to real results.
                Custom trajectories are defined and passed to PX4 using position and velocity setpoints. The trajectories were optimized and smoothed out by our flight controller for minimum jerk along the path. &lt;/p&gt;


        &lt;div style=&quot;text-align: center;&quot;&gt;
                &lt;h3&gt;Joint Controllers using ROS&lt;/h3&gt;
                &lt;img src=&quot;/images/projects/iarc/module-replacement.gif&quot; class=&quot;image&quot; style=&quot;max-width:50%;&quot; alt=&quot;&quot;&gt;
        &lt;/div&gt;
        &lt;p&gt;We utilised joint-transmission controllers in ROS to control the actuators of the module replacement mechanism with high precision.
                The quad mimics the mast motion with varying sea states using the ML feed to align the gripper mechanism with the module.
                Further, the end-effector's fine alignment is done using PID tuning of the alignment mechanism to capture the mast's motion accurately.  The team did the tuning based on the ML detection and the actuator specifications.
                Once aligned to the required proximity, a sequence of actions performed by the end-effector mechanism replaces the communication module.&lt;/p&gt;
&lt;hr&gt;
        &lt;/div&gt;

&lt;div id=&quot;Three&quot; class=&quot;tabcontent&quot;&gt;
&lt;h2&gt;Localisation&lt;/h2&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;Localisation is the method of localising oneself in an environment with respect to the initial position. One of the most popular methods of Localisation is SLAM (Simultaneous Localisation and Mapping).
        Visual SLAM extracts features from the environment to create a map and uses them to obtain the relative position. We have implemented ORB-SLAM2 for the localisation of the Daughter drone and RTK-GPS for the Mothership. &lt;/p&gt; 

&lt;div style=&quot;text-align: center;&quot;&gt;
        &lt;h3&gt;ORB SLAM-2&lt;/h3&gt;
        &lt;img src=&quot;/images/projects/iarc/orb.png &quot; class=&quot;image&quot; style=&quot;max-width:50%;&quot; alt=&quot;&quot;&gt;
&lt;/div&gt;
&lt;p&gt;&lt;b&gt; ORB-SLAM2&lt;/b&gt; provides significantly more accurate results over Visual Odometry by eliminating errors of drift. The key feature of ORB-SLAM2 is that it uses the same features/image for localisation, mapping, and detecting loop closure. Loop closure enables us to create a local map as well as apply global bundle adjustment.
        Camera used: R200 RGB-D camera. &lt;br&gt;
        &lt;b&gt;RGB-D camera&lt;/b&gt; provides more accurate results than Monocular as the scaling factor is obtained directly from a depth sensor.  It also performs faster than stereo camera configuration.
        The FPS of the camera is 60. It maintains accuracy for a maximum drone speed of 1.5 m/s.&lt;/p&gt;


&lt;div style=&quot;text-align: center;&quot;&gt;
        &lt;h3&gt;GPS-RTK&lt;/h3&gt;
        &lt;img src=&quot;/images/projects/iarc/rtk.png&quot; class=&quot;image&quot; style=&quot;max-width:50%;&quot; alt=&quot;&quot;&gt;
&lt;/div&gt;
&lt;p&gt;Real Time Kinematic is a technique used to increase the accuracy of GNSS positions using a fixed base station that wirelessly sends out correctional data to a moving receiver.The technique involves the measurement of the carrier phase of the satellite signal, which is then subject to some sophisticated statistical methods to align the phase of these signals to eliminate the majority of normal GPS type errors.
        The key to achieving centimetre-level positioning accuracy with RTK is the use of the GPS carrier phase signals. Carrier phase measurements are like precise tape measures from the base and rover antennas to the satellites. In the receiver, carrier phase measurements are made with millimetre-precision.
        RTK provides accuracy enhancements up to about 6-7 km from the base station&lt;/p&gt;


&lt;h2&gt;Machine Learning &amp; Perception&lt;/h2&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
        &lt;h3&gt;Mast Detection&lt;/h3&gt;
&lt;/div&gt;
&lt;p&gt;We used YOLOv4, which is a state-of-the-art object detection model to detect a target with high IOU(intersection over union). YOLOv4 uses new features like WRC, CSP, CmBN, SAT, Mish activation, Mosaic data augmentation, DropBlock regularization, and CIoU loss. It combines some of them to achieve state-of-the-art results: 43.5% AP (65.7% AP50) for the MS COCO dataset. These models are used to find the centre of the mast.&lt;/p&gt;
&lt;div class=&quot;row uniform 50%&quot;&gt;
        &lt;div class=&quot;6u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/iarc/board.gif&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
        &lt;div class=&quot;6u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/iarc/module-new.gif&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;hr&gt;

&lt;/div&gt;



&lt;script&gt;

const buttonElement = document.querySelectorAll('.tablinks');
const tabContent = document.querySelectorAll(&quot;.tabcontent&quot;);

tabContent[0].style.display = &quot;block&quot;;

buttonElement.forEach(function (i) {
    i.addEventListener('click', function (event) {

        for (let x = 0; x &lt; buttonElement.length; x++) {
            if (event.target.id == buttonElement[x].id) {
                buttonElement[x].className = buttonElement[x].className.replace(&quot; active&quot;, &quot;&quot;);
                tabContent[x].style.display = &quot;block&quot;;
                event.currentTarget.className += &quot; active&quot;;
            } else {
                tabContent[x].style.display = &quot;none&quot;;
                buttonElement[x].className = buttonElement[x].className.replace(&quot; active&quot;, &quot;&quot;);
            }
        }
        
    });
});
&lt;/script&gt;</description>
        <pubDate>Fri, 30 Oct 2020 00:00:00 +0530</pubDate>
        <link>robotics portfolio/projects/iarc</link>
        <guid isPermaLink="true">robotics portfolio/projects/iarc</guid>
        
        
      </item>
    
      <item>
        <title>Flipkart Grid 2.0</title>
        <description>&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;h4&gt;National Finalists of Flipkart Grid 2.0!!!!&lt;/h4&gt;
    &lt;img src=&quot;/images/projects/d2c/trophy.png&quot; class=&quot;image&quot; style=&quot;max-width:20%;&quot; alt=&quot;&quot;&gt;
&lt;/div&gt;

&lt;h3&gt;Autonomous Indoor Drone&lt;/h3&gt;
&lt;div class=&quot;row uniform 50%&quot;&gt;
    &lt;div class=&quot;6u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/d2c/cad.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
    &lt;div class=&quot;6u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/d2c/simcad.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;br&gt;

&lt;h3&gt;Abstract&lt;/h3&gt;
&lt;p&gt;Drones have recently garnered a lot of attention in all sorts of domains including supply chain. While autonomous drones have achieved decent maturity in outdoor environments, the conventional drones still struggle to perform in an indoor environment such as a warehouse. The main reason for this comes from the fact that in outdoor environments, drones could rely on global navigation systems such as GPS for their position and velocity estimates. However when it comes to an indoor environment there is a lot of scope of innovation of sensors and processing.&lt;/p&gt;

&lt;H3&gt;Problem Statement:&lt;/H3&gt;
&lt;ol&gt;
    &lt;b&gt;&lt;li&gt;&lt;h4&gt;Objective&lt;/h4&gt;&lt;/li&gt;&lt;/b&gt;
    &lt;ul&gt;
        &lt;li&gt;The objective of the problem statement is to come up with an autonomous drone which is capable to travel along a predefined trajectory&lt;/li&gt;
        &lt;li&gt;The drone should be able to course correct the trajectory to be able to achieve objectives such as crossing through some square frames (gate) or avoiding obstacles in its path&lt;/li&gt;
        &lt;li&gt;Parameters : 
            &lt;ol&gt;
                &lt;li&gt;Multi-rotor drone&lt;/li&gt;
                &lt;li&gt;Minimum payload : 2 Kg&lt;/li&gt;
                &lt;li&gt;Navigate in the aisle width of 5000mm&lt;/li&gt;
                &lt;li&gt;Autopilot, PID controlled &amp; obstacle avoidance features&lt;/li&gt;
            &lt;/ol&gt;
        &lt;/li&gt;
    &lt;/ul&gt;
    &lt;b&gt;&lt;li&gt;&lt;h4&gt;Trajectory Specification:&lt;/h4&gt;&lt;/li&gt;&lt;/b&gt;
    &lt;ul&gt;
        &lt;li&gt;The drone will travel along a straight aisle.&lt;/li&gt;
        &lt;li&gt;The aisle will have 15 gates which the drone has to pass through.&lt;/li&gt;
        &lt;li&gt;The gates can be placed anywhere in the aisle but will stay perpendicular to the aisle.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;b&gt;&lt;li&gt;&lt;h4&gt;Gate Specification:&lt;/h4&gt;&lt;/li&gt;&lt;/b&gt;
    &lt;ul&gt;
        &lt;li&gt;The gate will be a rectangular frame 550 x 1000 mm ( L x B )&lt;/li&gt;
        &lt;li&gt;The gate will be mounted on a frame at the height of 3000mm&lt;/li&gt;&lt;br&gt;
        &lt;div style=&quot;text-align: center;&quot;&gt;
            &lt;img src=&quot;/images/projects/d2c/ps.png&quot; class=&quot;image&quot; style=&quot;max-width:100%;&quot; alt=&quot;&quot;&gt;
        &lt;/div&gt;
    &lt;/ul&gt;
    
&lt;/ol&gt;


&lt;ul class=&quot;tab actions fit&quot;&gt;
    &lt;li&gt;&lt;button class=&quot;tablinks active  button fit&quot; id=&quot;One&quot;&gt;Mechanical&lt;/button&gt;&lt;/li&gt;
    &lt;li&gt;&lt;button class=&quot;tablinks button fit&quot; id=&quot;Two&quot;&gt;Controls&lt;/button&gt;&lt;/li&gt;
    &lt;li&gt;&lt;button class=&quot;tablinks button fit&quot; id=&quot;Three&quot;&gt;ML and pathplaning&lt;/button&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div id=&quot;One&quot; class=&quot;tabcontent&quot;&gt;
    &lt;div class=&quot;row uniform 50%&quot;&gt;
        &lt;div class=&quot;6u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt; My primary contribution lies here. I was responsible for designing the frame and performing structural as well as Dynamic analysis. &lt;br&gt;
            CAD is designed in &lt;b&gt;SolidWorks&lt;/b&gt; and Analysis was done in &lt;b&gt;Ansys&lt;/b&gt;. &lt;br&gt;
        A strong and sturdy carbon-fibre frame is chosen which is well capable of handling the stresses encountered during the mission
        
        The Centre of Mass lies below the plane of rotors. This provides inherent stability to the quadrotor. Being a uniform gravity environment, the quadrotor is an inherently Neutrally Stable System. The flight control algorithm ensures further stability of the system.&lt;/span&gt;&lt;/div&gt;
        &lt;div class=&quot;6u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/d2c/d2c2.jpg&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
    &lt;/div&gt;


    &lt;div style=&quot;text-align: center;&quot;&gt;&lt;button class=&quot;button&quot; id=&quot;toggle&quot; onclick=&quot;toggle()&quot;&gt;SHOW CAD&lt;/button&gt;&lt;/div&gt;&lt;br&gt;
&lt;div id=&quot;cad&quot; style=&quot;text-align: center; display: none;&quot;&gt;
    &lt;embed type=&quot;text/html&quot; src=&quot;/assets/d2c.html&quot; class=&quot;image fit&quot; height=&quot;250&quot;&gt;
    &lt;!-- &lt;iframe src=&quot;https://drive.google.com/file/d/1s3DOboV1j0a23tstK6038GusZBrJ3ufm/preview&quot; class=&quot;image&quot; style=&quot;max-width: 100%;&quot; title=&quot;Iframe Example&quot; frameborder=&quot;0&quot;&gt;&lt;/iframe&gt; --&gt;
&lt;/div&gt;

&lt;h3&gt;structure Analysis&lt;/h3&gt;
Material : Thornel MAT VMA (carbon fiber), maximum stress capability : 1.4e+09 Pa (N/m2) &lt;br&gt;
Analysis: Based on Von Mises yield criteria &lt;br&gt; &lt;br&gt;
&lt;div class=&quot;row uniform 50%&quot;&gt;
    &lt;div class=&quot;6u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/d2c/d2c6.PNG&quot; alt=&quot;&quot; /&gt;
        &lt;h4 style=&quot;text-align: center;&quot;&gt;With Payload&lt;/h4&gt;
        &lt;ul&gt;
            &lt;li&gt;Maximum stress on arms of model during flight is : 4.07e+08 Pa (N/m2)&lt;/li&gt;
            &lt;li&gt;Material’s yield stress is 3.4 the maximum stress experienced by it, hence frame will sustain&lt;/li&gt;
        &lt;/ul&gt;
    &lt;/span&gt;&lt;/div&gt;
    &lt;div class=&quot;6u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/d2c/d2c5.gif&quot; alt=&quot;&quot; /&gt;
        &lt;h4 style=&quot;text-align: center;&quot;&gt;Without Payload&lt;/h4&gt;
        &lt;ul&gt;
            &lt;li&gt;Maximum stress on arms of model during flight is : 4.019e+08 Pa (N/m2)&lt;/li&gt;
            &lt;li&gt;Material’s yield stress is 3.5 the maximum stress experienced by it, hence frame will sustain&lt;/li&gt;
        &lt;/ul&gt;
    &lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h3&gt;Modal (Vibration) Analysis&lt;/h3&gt;
Variation of displacement amplitude with different exciting frequencies for our quadrotor &lt;br&gt; &lt;br&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/images/projects/d2c/vibration.PNG&quot; class=&quot;image&quot; style=&quot;max-width:100%;&quot; alt=&quot;&quot;&gt;
&lt;/div&gt;
&lt;hr /&gt;  
&lt;/div&gt;

&lt;div id=&quot;Two&quot; class=&quot;tabcontent&quot;&gt;
    We are using PX4 Software-In-The-Loop
     (SITL), which is a very important tool to model the behaviour of the quadrotor in a simulated world.
    &lt;h3&gt;Decision Making:&lt;/h3&gt;
    &lt;div class=&quot;row uniform 50%&quot;&gt;
        &lt;div class=&quot;6u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/d2c/decision.png&quot;  alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
        &lt;div class=&quot;6u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;
            &lt;ul&gt;
                &lt;br&gt;
                &lt;li&gt;Perception node maintains a python dictionary of positions of all the 15 frames&lt;/li&gt;
                &lt;li&gt;If the quadrotor has passed through i th frame, and the location of i+1 th frame is still unknown, then it begins to perform a left-right search manoeuvre&lt;/li&gt;
                &lt;li&gt;If the position of i+1 th frame is known, then the path planning node generates a optimal path avoiding all obstacles                &lt;/li&gt;
                &lt;li&gt;This path is fed to the FCU via the rostopic /mavros/setpoint_raw/position&lt;/li&gt;
            &lt;/ul&gt;
        &lt;/span&gt;&lt;/div&gt;
    &lt;/div&gt;
    &lt;hr&gt;
&lt;/div&gt;
&lt;div id=&quot;Three&quot; class=&quot;tabcontent&quot;&gt;
    &lt;h4&gt;Frame Detection&lt;/h4&gt;
    &lt;div class=&quot;row uniform 50%&quot;&gt;
        &lt;div class=&quot;6u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;
            &lt;br&gt;
            camera feed in the bottom right. &lt;br&gt; &lt;br&gt;
            The frame detection algorithm first detects the corners and then applies matrix transformations to obtain the locations of the frames. &lt;br&gt; &lt;br&gt;
            The depth camera feed is used to correctly distinguish between frames that appear to be intersecting. &lt;br&gt;
        &lt;/span&gt;&lt;/div&gt;
        &lt;div class=&quot;6u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/d2c/ml.jpg&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
    &lt;/div&gt;

    &lt;h4&gt;Localisation&lt;/h4&gt;
    ORBSLAM2 is being used for localisation. &lt;br&gt;&lt;br&gt; It extracts key features form the environment and fuses their relative variation with the IMU data to estimate the pose.
The arrow in the point cloud shows the estimated position and orientation of the quadrotor. &lt;br&gt;&lt;br&gt;
The top right terminal is showing actual pose by mavros and bottom right is pose measured by integrating SLAM and lidar. We see that they are nearly equal. &lt;br&gt; &lt;br&gt;
&lt;div class=&quot;12u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/d2c/localization.jpg&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
ORB SLAM is most efficient module for indoor localisation and consists of robust feature detection and matching algorithms. Moreover fusing the LIDAR data make it much more accurate. The accuracy can be further improved in real world testing, in which more features are available compared to a simulated world.


&lt;hr&gt;

&lt;/div&gt;


&lt;div id=&quot;&quot; style=&quot;text-align: center ;&quot;&gt;
    &lt;h4&gt;Our entry for Flipkart Grid 2.0 Nation Finale submission:
    &lt;/h4&gt;
    &lt;iframe src=&quot;https://drive.google.com/file/d/1s3DOboV1j0a23tstK6038GusZBrJ3ufm/preview&quot; class=&quot;image&quot; style=&quot;width: 100%; height: 25em;&quot; title=&quot;Iframe Example&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;script&gt;
    function toggle() {
        btn = document.getElementById('toggle');
        cad = document.getElementById('cad')
        if(cad.style.display =='none')
        {
            cad.style.display = 'block'
            btn.innerHTML = 'HIDE CAD'
        }
        else
        {
            cad.style.display = 'none'
            btn.innerHTML = 'SHOW CAD'
        }
    }
&lt;/script&gt;

&lt;script&gt;

    const buttonElement = document.querySelectorAll('.tablinks');
    const tabContent = document.querySelectorAll(&quot;.tabcontent&quot;);
    
    tabContent[0].style.display = &quot;block&quot;;
    
    buttonElement.forEach(function (i) {
        i.addEventListener('click', function (event) {
    
            for (let x = 0; x &lt; buttonElement.length; x++) {
                if (event.target.id == buttonElement[x].id) {
                    buttonElement[x].className = buttonElement[x].className.replace(&quot; active&quot;, &quot;&quot;);
                    tabContent[x].style.display = &quot;block&quot;;
                    event.currentTarget.className += &quot; active&quot;;
                } else {
                    tabContent[x].style.display = &quot;none&quot;;
                    buttonElement[x].className = buttonElement[x].className.replace(&quot; active&quot;, &quot;&quot;);
                }
            }
            
        });
    });
    &lt;/script&gt;</description>
        <pubDate>Thu, 29 Oct 2020 00:00:00 +0530</pubDate>
        <link>robotics portfolio/projects/d2c</link>
        <guid isPermaLink="true">robotics portfolio/projects/d2c</guid>
        
        
      </item>
    
      <item>
        <title>Interiit9</title>
        <description>&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;h4&gt;Won A Bronze Medal In Inter IIT Tech Meet for AgroBot Design Innovation&lt;/h4&gt;
    &lt;img src=&quot;/images/projects/interiit9/bronze.png&quot; class=&quot;image&quot; style=&quot;max-width:20%;&quot; alt=&quot;&quot;&gt;
&lt;/div&gt;

&lt;h3&gt;Abstract&lt;/h3&gt;
&lt;p&gt; 
    The agro-based industry is regarded as the sunrise sector of the Indian economy because of its large potential for growth, employment, and income generation. Farmers must meet the changing needs of our planet and the expectations of regulators, consumers, and food processors, and retailers.
     Cost-effective, eco-friendly, and easily operable agricultural bots are in demand to give a boost to the economy.&lt;/p&gt;

&lt;br&gt;
&lt;h3&gt;Problem Statement&lt;/h3&gt;
&lt;p&gt;
    RuTAG (Rural Technology Action Group) Conducted the Competition during the 9th Inter IIT Tech Meet for mechanised farming in hilly terrains
&lt;/p&gt;

&lt;h3&gt;Solution&lt;/h3&gt;
&lt;ul&gt;
    &lt;li&gt;We provided a System of Modular robots with different accessories attached.&lt;/li&gt;
    &lt;div class=&quot;row uniform 50%&quot;&gt;
        &lt;div class=&quot;4u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/interiit9/bot1.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
        &lt;div class=&quot;4u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/interiit9/bot2.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
        &lt;div class=&quot;4u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/interiit9/bot3.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
    &lt;/div&gt;
    
    &lt;li&gt;We focused three main accessories &lt;/li&gt;
    &lt;div class=&quot;row uniform 50%&quot;&gt;
        &lt;div class=&quot;4u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/interiit9/transplant.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
        &lt;div class=&quot;4u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/interiit9/seed.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
        &lt;div class=&quot;4u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/interiit9/weed.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/ul&gt;



&lt;h3&gt;My Contribution&lt;/h3&gt;
&lt;ul&gt;
    &lt;li&gt;&lt;b&gt;Leading&lt;/b&gt; the whole team&lt;/li&gt;
    &lt;li&gt;Design of Modular chassis and transplantation mechanisms&lt;/li&gt;
&lt;/ul&gt;</description>
        <pubDate>Wed, 28 Oct 2020 00:00:00 +0530</pubDate>
        <link>robotics portfolio/projects/interiit</link>
        <guid isPermaLink="true">robotics portfolio/projects/interiit</guid>
        
        
      </item>
    
      <item>
        <title>Interiit</title>
        <description>&lt;h3&gt;About the Competition&lt;/h3&gt;
&lt;p&gt;This Competition was held during the 8th Inter IIT Tech Meet. During this meet, different tech competitions are conducted between IITs.
    One of them was the &quot;DIC's Terrace Farming Challenge for Hilly areas&quot;.
    The task was to design an autonomous robot that can climb steps of 40cm and perform basic farming tasks like Cutting, Plucking, etc.
     &lt;/p&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/images/projects/interiit/interiit1.jpeg&quot; class=&quot;image&quot; style=&quot;max-width:50%;&quot; alt=&quot;&quot;&gt;&lt;br&gt; &lt;br&gt;
    &lt;a class=&quot;button&quot; target=&quot;blank&quot; href=&quot;/assets/interiit_ps.pdf&quot;&gt;Problem Statement&lt;/a&gt;
&lt;/div&gt;

&lt;hr&gt;

&lt;h3&gt;Our robot model&lt;/h3&gt;
&lt;p&gt;We had to come up with a design which will be compact and can perform given tasks including the climbing mechanism. after a week of brainstorming we came up with a design which includes a lead screw for the climbing mechanism and a rectangular shell around the bot which will perform the task of plowing and cutting. we also include a simple pipe with a funnel for seeding.
    This idea lead us to stood 2nd in indeation phase. 
    Here are the pictures illustrating how our bot looks like: &lt;/p&gt;
&lt;div class=&quot;row uniform 50%&quot;&gt;
    &lt;div class=&quot;6u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/interiit/interiit2.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
    &lt;div class=&quot;6u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/interiit/interiit3.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h3&gt;climbing mechanism&lt;/h3&gt;
&lt;p&gt;The climbing mechanism includes series of motions of lead screw and driving wheels which will cause to bot lift up and move forward.
    Following image will illustrate the overall mechanism :
&lt;/p&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/images/projects/interiit/interiit4.gif&quot; class=&quot;image&quot; style=&quot;max-width:50%;&quot; alt=&quot;&quot;&gt;&lt;br&gt; &lt;br&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h3&gt;final assembly of bot and competition&lt;/h3&gt;
&lt;p&gt;
    &lt;div class=&quot;row uniform 50%&quot;&gt;
        &lt;div class=&quot;4u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/interiit/interiit5.jpg&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
        &lt;div class=&quot;4u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/interiit/interiit6.jpg&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
        &lt;div class=&quot;4u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/interiit/interiit7.jpg&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;
    After weeks of effort, we could complete the hardware assembly a day before the competition and that's why we didn't get time for testing.
    During the competition, due to electrical failures, we could not perform tasks.
     Though we didn't win the competition the overall experience of this project was life-changing for me, 
     this Tech Meet changed my perspective of thinking in all aspects. Also, the train journey, debugging in the train, 
     finding tools at late night in place which completely unknown to us was less than an adventure!
&lt;/p&gt;</description>
        <pubDate>Tue, 27 Oct 2020 00:00:00 +0530</pubDate>
        <link>robotics portfolio/projects/interiit</link>
        <guid isPermaLink="true">robotics portfolio/projects/interiit</guid>
        
        
      </item>
    
      <item>
        <title>Team Stride</title>
        <description>&lt;h3&gt;About stride&lt;/h3&gt;
&lt;p&gt;Stride is the student technical team at IIT Bombay, focusing on Qudrpuped robots for manoeuvering through rough terrains&lt;/p&gt;

&lt;h3&gt;My contribution&lt;/h3&gt;
&lt;ul&gt;
    &lt;li&gt;Coded an &lt;b&gt;Inverse kinematics&lt;/b&gt; algorithm on micro-controller to execute the motion of quadruped robot&lt;/li&gt;
    &lt;li&gt;Designed a Controller to integrate the functionality components like grippers, pneumatic cylinders, motors, etc&lt;/li&gt;
    &lt;li&gt;Created low pass filters using op-amp and RC combinations to reduce noise in signal for controlling motors&lt;/li&gt;

&lt;/ul&gt;</description>
        <pubDate>Mon, 26 Oct 2020 00:00:00 +0530</pubDate>
        <link>robotics portfolio/projects/stride</link>
        <guid isPermaLink="true">robotics portfolio/projects/stride</guid>
        
        
      </item>
    
      <item>
        <title>Project Ethan</title>
        <description>&lt;h3&gt;About Project&lt;/h3&gt;
&lt;p&gt;
    During the pandemic period, I applied for a tech team.
    I had to solve one problem statement to pass the recruitment process.
    So, this project was based on that problem statement.
    It includes &lt;b&gt;ROS+Gazebo simulations&lt;/b&gt; along with mechanical design.
&lt;/p&gt;
&lt;hr&gt;
&lt;h3&gt;Problem Statement&lt;/h3&gt;
&lt;div class=&quot;12u&quot; style=&quot;text-align: center;&quot;&gt;&lt;span class=&quot;image fit&quot; style=&quot;text-align: center;&quot;&gt;&lt;img
            src=&quot;/images/projects/ethan/ethan1.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
&lt;p&gt;
    The Robot is launched in an unknown apartment, it has to find the passcode of safe which is located in the same
    apartment. The digits of passcode are written on walls at different locations robot has to recognize this digits and
    decode the passcode, the hint for passcode sequence is 1st digit is red, 2nd is green, 3rd is yellow, 4th is blue
    and 5th is orange. Once bot decodes the passcode and saves, it has to search for safe and press the keys for
    unlocking the safe!
    &lt;br&gt;
    &lt;u&gt;&lt;b&gt;But, here is the catch ! &lt;/b&gt;&lt;/u&gt;: Safe is at 100cm and appartment is armed with lasers which will detect any
    thing above
    50cm. So, our bot design should be in a such way that it will have height less than 50cms and will be able to extend
    itself upto 100cms !
&lt;/p&gt;
&lt;hr&gt;
&lt;h3&gt;Here is how our bot looks!&lt;/h3&gt;
&lt;div class=&quot;12u&quot; style=&quot;text-align: center;&quot;&gt;&lt;span class=&quot;image fit&quot; style=&quot;text-align: center;&quot;&gt;&lt;img
            src=&quot;/images/projects/ethan/ethan2.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
&lt;hr&gt;
&lt;h3&gt;Final Results:&lt;/h3&gt;

&lt;div class=&quot;row uniform 50%&quot;&gt;
    &lt;div class=&quot;6u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/ethan/ethan3.gif&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
    &lt;div class=&quot;6u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/ethan/ethan4.gif&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;</description>
        <pubDate>Mon, 26 Oct 2020 00:00:00 +0530</pubDate>
        <link>robotics portfolio/projects/ethan</link>
        <guid isPermaLink="true">robotics portfolio/projects/ethan</guid>
        
        
      </item>
    
      <item>
        <title>Arduino Quadcopter</title>
        <description>&lt;h3&gt;Arduino Quadcopter from scratch&lt;/h3&gt;
&lt;p&gt;Every engineer wishes to build a drone at least once in his life. I also dreamed about the same and took a step to
    make it totally from scratch without any readymade flight controllers.
    The motivation to build from scratch was to learn PID. I wanted to learn PID and apply it in the real-life. &lt;/p&gt;
&lt;hr&gt;
&lt;h3&gt;pid&lt;/h3&gt;
&lt;p&gt;
    The basic goal of PID is to reach the desired state under given uncertainties. In case of Quadcopter there are
    uncertainties like wind, center of mass position, etc. You have tune PID parameters to
    obtain optimum results. From the following images, you can get an Intuitive idea of PID
&lt;div class=&quot;row uniform 50%&quot;&gt;
    &lt;div class=&quot;6u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/quad/quad1.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
    &lt;div class=&quot;6u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/quad/quad2.gif&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;br&gt; for more brief and clear idea you can go through my PID tutorial &lt;br&gt;&lt;br&gt;
    &lt;a href=&quot;/projects/pid_tut&quot; class=&quot;button&quot;&gt;PID tutorial&lt;/a&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h3&gt;2D model approximation for PID testing&lt;/h3&gt;
&lt;p&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;/images/blogs/pid/pid.gif&quot; class=&quot;image&quot; style=&quot;max-width:50%;&quot; alt=&quot;&quot;&gt;&lt;br&gt; &lt;br&gt;
&lt;/div&gt;
Before applying PID on the quadcopter, I had to find an alternative model that will be safer to test so that, I can play
around with it and see the response of different parameters of PID.
&lt;br&gt; The 2D model approximation shown in the above image is best to do that. with the help of this model, I could learn
more about PID and its parameter's response. The one more major learning was to learn how to apply filters like
&lt;b&gt;complementary filters, Kalman filters&lt;/b&gt; to reduce the noise in the gyroscope due to vibrations of the frame.
you can watch the full video of the model that I made... &lt;br&gt;

&lt;/p&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;a class=&quot;popup-youtube button&quot; href=&quot;https://www.youtube.com/watch?v=TlcQ_J3_AQk&quot;&gt;Watch Video&lt;/a&gt;&lt;br&gt;
&lt;/div&gt;

&lt;hr&gt;
&lt;h3&gt;
    &lt;li&gt;Components and Accessories&lt;/li&gt;
&lt;/h3&gt;
&lt;p&gt;
&lt;div class=&quot;box alt&quot;&gt;
    &lt;div class=&quot;row uniform 50%&quot;&gt;
        &lt;div class=&quot;4u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/quad/quad3.jpg&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
        &lt;div class=&quot;4u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/quad/quad4.jpg&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
        &lt;div class=&quot;4u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/quad/quad5.jpg&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;


&lt;hr&gt;
&lt;h3&gt;
    &lt;li&gt;Failures&lt;/li&gt;
&lt;/h3&gt;
&lt;p&gt;

    As there was no one to guide me on how to make it properly, I failed too many times. Things went wrong when I
    started testing.
    I harmed my self two times, broke the frame, the battery swelled and I had to replace it 3 times
&lt;div class=&quot;box alt&quot;&gt;
    &lt;div class=&quot;row uniform 50%&quot;&gt;
        &lt;div class=&quot;4u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/quad/quad6.jpg&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
        &lt;div class=&quot;4u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/quad/quad7.jpg&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
        &lt;div class=&quot;4u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/quad/quad8.jpg&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;div class=&quot;12u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/quad/quad9.jpg&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/p&gt;

&lt;hr&gt;
&lt;h3&gt;
    &lt;li&gt;Final Results&lt;/li&gt;
&lt;/h3&gt;
&lt;p&gt;
    After months of efforts I could reach my goal!!!!!
&lt;/p&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;a class=&quot;popup-youtube button&quot; href=&quot;/images/projects/quad/hover.mp4&quot;&gt;Watch hover video&lt;/a&gt;&lt;br&gt;&lt;/div&gt;</description>
        <pubDate>Sun, 25 Oct 2020 00:00:00 +0530</pubDate>
        <link>robotics portfolio/projects/quad</link>
        <guid isPermaLink="true">robotics portfolio/projects/quad</guid>
        
        
      </item>
    
      <item>
        <title>Pluto Hackathon</title>
        <description>&lt;h3&gt;About Hackathon:&lt;/h3&gt;
&lt;p&gt;
    Aero modeling club IIT BOMBAY, conducted a very interesting hackathon in collaboration with a company named &lt;a href=&quot;https://www.dronaaviation.com/&quot;&gt;&quot;Drona Aviation&quot;&lt;/a&gt;. They gave us their drones and asked to solve the problem statement using their drones.
    The problem statement which was given to us was 'FLAME SENSING DRONE'
&lt;/p&gt;
&lt;hr&gt;    
&lt;h3&gt;our solution&lt;/h3&gt;
&lt;div id=&quot;&quot; style=&quot;text-align: center ;&quot;&gt;
    &lt;h4&gt;Simulation Video&lt;/h4&gt;
    &lt;iframe src=&quot;https://youtube.com/embed/hG6be54gPwU&quot; class=&quot;image&quot; style=&quot;max-width: 100%;&quot; title=&quot;Iframe Example&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;</description>
        <pubDate>Sat, 24 Oct 2020 00:00:00 +0530</pubDate>
        <link>robotics portfolio/projects/pluto</link>
        <guid isPermaLink="true">robotics portfolio/projects/pluto</guid>
        
        
      </item>
    
      <item>
        <title>Cozmo Clench</title>
        <description>&lt;h3&gt;About Competition: &lt;/h3&gt;
&lt;p&gt;
    It was my first competition as a fresher to represent IIT Bombay in any robotic competition. It was organized during
    &lt;a href=&quot;https://techfest.org/&quot; target=&quot;blank&quot;&gt;TechFest&lt;/a&gt; (Asia's Largest technical festival).
&lt;/p&gt;
&lt;hr&gt;
&lt;h3&gt;Problem Statement:&lt;/h3&gt;
&lt;p&gt;
    Your bot is in an arena, where there are some empty spaces. The robot has to grab boxes placed in the same arena and
    fill those empty spaces.
    &lt;div style=&quot;text-align: center;&quot;&gt;
        &lt;div class=&quot;12u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/images/projects/cozmo/cozmo1.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
        &lt;a class=&quot;button&quot; target=&quot;blank&quot; href=&quot;/assets/Cozmo-Clench.pdf&quot;&gt;View Full Problem Statement&lt;/a&gt;

    &lt;/div&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h3&gt;My bot!&lt;/h3&gt;
&lt;div id=&quot;&quot; style=&quot;text-align: center ;&quot;&gt;
    &lt;h4&gt;Simulation Video&lt;/h4&gt;
    &lt;iframe src=&quot;https://youtube.com/embed/pMcU77L2mfw&quot; class=&quot;image&quot; style=&quot;max-width: 100%;&quot; title=&quot;Iframe Example&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;</description>
        <pubDate>Fri, 23 Oct 2020 00:00:00 +0530</pubDate>
        <link>robotics portfolio/projects/cozmo</link>
        <guid isPermaLink="true">robotics portfolio/projects/cozmo</guid>
        
        
      </item>
    
  </channel>
</rss>
